[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JASP for Audit",
    "section": "",
    "text": "Preface\nThe JASP for Audit User Manual provides detailed instructions and best practices for working with the Audit module in the free and open-source software JASP. It covers various aspects, including data import and export, analysis techniques, and interpretation of results.\nThe Statistical Auditing Group at Nyenrode Business University, which develops and maintains JASP for Audit, curates the manual to ensure users have accurate and up-to-date information.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Getting Started",
    "section": "",
    "text": "Downloading JASP\nStatistical theory is fundamental to many auditing procedures. To perform these procedures effectively, auditors need user-friendly software for statistical analyses and the knowledge to interpret the results. JASP (JASP Team, 2025) is an open-source, free-of-charge, cross-platform statistical software program that supports statistical auditing through its Audit module (Derks et al., 2021, 2023).\nThe Audit module (i.e., JASP for Audit) enables auditors to plan, execute, and interpret a wide range of statistical auditing procedures using state-of-the-art statistical methods, thereby reducing programming errors and simplifying the process. Tailored for auditors, the module features an intuitive interface that aligns with audit processes and international standards on auditing. In addition to standard frequentist methods, the Audit module incorporates Bayesian methods to enhance audit transparency and efficiency by utilizing existing information.\nIn summary, the Audit module takes care of the complex statistical work, enabling you to concentrate on interpreting the results of your analysis. The remaining paragraphs in this chapter discuss how to get started using JASP for Audit.\nJASP for Audit is part of JASP, which can be freely downloaded from www.jasp-stats.org. Click the ‘Download JASP’ button on the homepage to access the download page and choose your preferred installation. JASP is available for Windows, MacOS, Linux, and Chrome OS.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#enabling-the-audit-module",
    "href": "introduction.html#enabling-the-audit-module",
    "title": "Getting Started",
    "section": "Enabling the Audit module",
    "text": "Enabling the Audit module\nAfter opening JASP, you will see the following main menu bar at the top of the screen.\n\n\n\n\n\nTo find the Audit module, click the ‘+’ icon on the right of this menu bar. A different menu will appear on the right side which shows all available modules. Check the box next to ‘Audit’ to make the module visible in the main menu bar. You can now access the Audit module and its analyses by clicking its module icon in the menu bar (see image below).\n\n\n\n\n\nYou can find detailed instructions for each analysis in the Audit module in the corresponding chapter of this manual.",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "introduction.html#miscellaneous",
    "href": "introduction.html#miscellaneous",
    "title": "Getting Started",
    "section": "Miscellaneous",
    "text": "Miscellaneous\nThe following paragraphs detail miscellaneous features, including where to locate help files and how to the reliability of the statistical results is ensured.\n\nHelp files\nOnce you open an analysis in the Audit module, you can click the blue ‘i’ icon next to the analysis title to access a help file that explains its functionality. Additional help files for certain settings can be accessed by clicking the blue ‘i’ icon next to those settings.\n\n\n\n\n\n\n\nValidation of statistical results\nThe statistical results generated by the Audit module are based on the R package jfa (Derks, 2025). For comprehensive documentation and information on the benchmarks used for validation, please visit the package website at https://koenderks.github.io/jfa/.\n\n\n\n\n\n\nDerks, K. (2025). jfa: Statistical methods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R. (2021). JASP for Audit: Bayesian tools for the auditing practice. Journal of Open Source Software, 6(68), 2733.\n\n\nDerks, K., Swart, J. de, & Wetzels, R. (2023). Open-source software als brug tussen de auditor en de statisticus. Maandblad Voor Accountancy En Bedrijfseconomie, 97(1/2), 17–28. https://doi.org/10.5117/mab.97.87480\n\n\nJASP Team. (2025). JASP (Version 0.19.3)[Computer software]. https://jasp-stats.org/",
    "crumbs": [
      "Getting Started"
    ]
  },
  {
    "objectID": "chap-workflow.html",
    "href": "chap-workflow.html",
    "title": "1  Sampling Workflow",
    "section": "",
    "text": "1.1 The four stages of the sampling workflow\nThe goal of statistical audit sampling is to infer the misstatement in a population based on a representative sample. This can be challenging, but the Audit module simplifies the process into four stages: planning, selection, execution, and evaluation.\nMore detailed information about the individual stages in the audit sampling workflow is provided below.\nIn the planning stage, you determine the sample size needed to support the assertion that the population’s misstatement is below the performance materiality. This involves using prior audit outcomes and information about inherent risk and control risk. Expectations about error rates also influence the sample size required to maintain statistical confidence.\nUsing the sample size from the planning stage, you select a statistically representative sample. Each sampling unit receives an inclusion probability, and units are selected based on these probabilities. Monetary unit sampling assigns probabilities to individual monetary units, making higher-value items more likely to be selected. Record sampling assigns equal probabilities to all items.\nIn the execution stage, you assess the correctness of selected items. The simplest method categorizes items as correct or incorrect, while a more accurate method considers the true value (audit value) of items. Annotating samples with audit values provides a more precise estimate of misstatement. If book values are unavailable, use the correct/incorrect method.\nIn the evaluation stage, you use the annotated sample to infer the total misstatement in the population. Statistical techniques calculate a projected maximum misstatement, and the population is approved if this is below the performance materiality.\nThis manual emphasizes the practical application of the audit sampling workflow in JASP. For a deeper understanding of the statistical theory behind the four stages of the audit sampling workflow, read the free online book Statistical Audit Sampling with R.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-workflow.html#practical-example",
    "href": "chap-workflow.html#practical-example",
    "title": "1  Sampling Workflow",
    "section": "1.2 Practical example",
    "text": "1.2 Practical example\nThe Audit module in JASP offers two ways to navigate the audit sampling workflow: the Sampling Workflow analysis, which guides you through all four stages, and individual analyses for Planning, Selection, and Evaluation. This chapter uses the classical sampling workflow analysis to explain the Audit module’s core functionality. Note that a Bayesian variant of the sampling workflow is also available.\nLet’s explore an example of the audit sampling workflow. To follow along, open the ‘Testing for Overstatements’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Testing for Overstatements’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 3500 rows and three columns: ‘ID’, ‘bookValue’, and ‘auditValue’. The ‘ID’ column represents the identification number of the items in the population. The ‘bookValue’ column shows the recorded values of the items, while the ‘auditValue’ column displays the true values. The ‘auditValue’ column is included for illustrative purposes, as auditors typically know the true values only for the audited sample, not for all items in the population.\n\n\n\n\n\n\n1.2.1 Stage 1: Planning\nTo start the sampling workflow, click on the Audit module icon and select ‘Sampling Workflow’. This will open the following interface, where you need to specify the settings for the statistical analysis.\n\n\n\n\n\nThe following five settings are required:\n\nIndicate the variables: First, enter the variable indicating the identification numbers of the items in the corresponding box. Optionally, if you have access to the book values of the items, you can enter this variable as well.\nSampling objectives: Next, formulate your sampling objectives. Enable the ‘Performance materiality’ objective if you want to test whether the total misstatement in the population exceeds a certain limit (i.e., the performance materiality). This approach enables you to plan a sample such that, when the sample meets your expectations, the maximum error is said to be below performance materiality. Enable the ‘Minimum precision’ objective if you want to obtain a required minimum precision when estimating the total misstatement in the population. This approach enables you to plan a sample such that, when the sample meets expectations, the uncertainty of your estimate is within a tolerable percentage. In the example, we choose a performance materiality of 3.5%.\nExpected misstatement: Then, indicate how many misstatements are tolerable in the sample. In the example, we choose to tolerate one full misstatement in the sample.\nPrior information: Additionally, indicate the risks of material misstatement via the audit risk model. According to the Audit Risk Model, audit risk can be divided into three constituents: inherent risk, control risk, and detection risk. Inherent risk is the risk posed by an error in a financial statement due to a factor other than a failure of internal controls. Control risk is the probability that a material misstatement is not prevented or detected by the internal control systems of the company (e.g., computer-managed databases). Both these risks are commonly assessed by the auditor on a 3-point scale consisting of low, medium, and high. Detection risk is the probability that an auditor will fail to find material misstatements in an organization’s financial statements. For a given level of audit risk, the tolerable level of detection risk bears an inverse relationship to the other two assessed risks. Intuitively, a greater risk of material misstatement should require a lower tolerable detection risk and, accordingly, more persuasive audit evidence. In this example, we choose to set all risks to ‘High’ and solely rely on evidence from substantive testing.\n\nThe primary output from the planning stage, shown below, indicates that a minimum sample size of 134 sampling units is required to achieve 95% assurance that the misstatement in the population is below 3.5%, while allowing for one misstatement in the sample.\n\n\n\n\n\n\nNext stage: Finally, progress to the selection stage by clicking the ‘To Selection’ button.\n\nFor a more detailed explanation of the settings and output in the planning stage, see Chapter 2.\n\n\n1.2.2 Stage 2: Selection\nIn the selection stage, you must select the 134 sampling units from the population. Once the ‘To Selection’ button is pressed, the interface from the selection stage opens.\n\n\n\n\n\nThe following four settings are required:\n\nRandomness: Begin by selecting the settings related to randomness in the selection procedure. The seed setting is important as it ensures that random procedures are reproducible, allowing for consistent results across multiple runs. A random number will be chosen each time you start the analysis. Additionally, the ‘Randomize item order’ setting is available to randomly shuffle the rows in the dataset, which can help mitigate any biases that might arise from the original order of the data.\nSampling units: Next, specify the sampling units for the selection process. These units can either be items or monetary units. If no book value variable is provided, the sampling units default to ‘Items’, enabling attribute sampling. Conversely, if a book value variable was indicated during the planning stage, the sampling units default to ‘Monetary units’, facilitating monetary unit sampling (MUS). MUS is particularly useful for auditing financial data as it considers the monetary value of each unit.\nSampling method: Then, choose the selection method to be used in the sampling process. The available algorithms include:\n\n\nFixed interval sampling: This method selects units at regular intervals from the dataset, ensuring a systematic sampling approach.\nCell sampling: This technique involves dividing the dataset into cells and randomly selecting units from each cell, promoting a systematic sampling approach with a bit of randomness.\nRandom sampling: This approach randomly selects units from the entire dataset, providing a simple yet effective method for ensuring randomness.\n\nThe primary output from the selection stage, as shown in the first table below, reveals that 134 sampling units were selected from 134 items. The sample’s total value amounts to €67,821.22, representing 4.8% of the total population value. The second table provides details specific to interval selection using monetary unit sampling. It indicates the number of items selected in the ‘Top stratum’, which includes all items larger than a single interval (for fixed interval selection). In this instance, there were 0 items in the top stratum.\n\n\n\n\n\n\nNext stage: Finally, progress to the execution stage by clicking the ‘To Execution’ button.\n\n\n\n1.2.3 Stage 3: Execution\nIn the execution stage, you must judge the fairness of the 134 sampled items. Once the ‘To Execution’ button is pressed, the interface from the execution stage opens.\n\n\n\n\n\nThe following four settings are required:\n\nAnnotation method: First, decide how to annotate the selected items. You have two choices:\n\nAudit value: Annotate the items with their audit (true) values. This method is recommended (and automatically selected) when the items have a monetary value.\nCorrect / Incorrect: Annotate the items as correct (0) or incorrect (1). This method is recommended (and automatically selected) when the items do not have a monetary value.\n\nColumn names: Next, specify the names of the two columns that will be added to the dataset. The first column name will indicate the result of the selection, while the second column name will contain the annotation of the items. Click the ‘Continue’ button to confirm the settings and open the data viewer.\nAnnotating items: Then, use the data viewer to annotate the selected items with their book value. For example, in this case, item 50826 (row 25, highlighted in red) had a book value of €333.03 but a true value of €200. The remaining items have correctly reported book values.\nNext stage: Finally, progress to the evaluation stage by clicking the ‘To Evaluation’ button.\n\n\n\n1.2.4 Stage 4: Evaluation\nIn the evaluation stage, you assess the misstatement in the sample and extrapolate it to the entire population. Once you press the ‘To Evaluation’ button, the interface for the evaluation stage will open.\n\n\n\n\n\nThe following setting is required:\n\nAnnotation variable: Specify the variable that contains the annotation of the items in the corresponding box.\n\nThe following setting is optional:\n\nAdditional tables: It is recommended to request the ‘Misstated items’ table from the ‘Report’ section. This table displays the items in the sample where the book value did not match the true value. Additional tables and figures to clarify the output, which will be discussed in Chapter 4, can be requested here as well.\n\nThe primary output from the evaluation stage, as shown in the first table below, indicates that the most likely misstatement in the population is estimated to be 0.003, or 0.3%. The 95% upper bound for this estimate is 0.027, or 2.7%. This upper bound is lower than the performance materiality of 3.5%, meaning the auditor has achieved at least 95% assurance that the population misstatement is below the performance materiality.\n\n\n\n\n\nBased on the results of this statistical analysis, the auditor concludes that the population is free of material misstatement.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Workflow</span>"
    ]
  },
  {
    "objectID": "chap-planning.html",
    "href": "chap-planning.html",
    "title": "2  Planning",
    "section": "",
    "text": "2.1 Purpose of the analysis\nThis chapter is about the ‘Planning’ analysis in the ‘Audit Sampling’ section of the module.\nThe goal of the planning analysis is to determine the minimum sample size needed to meet the audit’s objectives. For example, a common audit objective is to obtain a specific level of confidence that the misstatement in the population is below the tolerable misstatement rate. This rate can be expressed as a monetary amount, known as performance materiality.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planning</span>"
    ]
  },
  {
    "objectID": "chap-planning.html#practical-example",
    "href": "chap-planning.html#practical-example",
    "title": "2  Planning",
    "section": "2.2 Practical example",
    "text": "2.2 Practical example\nLet’s consider an example of a planning analysis. Imagine we are auditing a population of 1,000 items with a total value of €1,000,000. In this scenario, we aim to determine the minimum sample size required to conclude, with 95% confidence, that the population does not contain misstatements exceeding the performance materiality of €30,000, which is 3% of the total value. Furthermore, we aim to incorporate a buffer and approve the population if a single misstatement is identified in the sample.\n\n2.2.1 Main settings\nTo plan the minimum sample size for this audit objective, we open the ‘Planning’ analysis within the Audit module. The interface for the planning analysis is displayed below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nSampling objectives: Performance materiality: In this section, we can input the performance materiality either as a percentage (relative) or as a monetary amount (absolute). If we choose to enter it as a monetary amount, we must also specify the number of units in the population. Here, we enter €30,000 as the absolute performance materiality.\nSampling objectives: Minimum precision: We can choose this setting if we want to identify the misstatement in the population with a specified minimum uncertainty (i.e., the difference between the most likely misstatement and the upper limit for the misstatement). However, since this is not relevant to our audit objective, we leave this box unchecked.\nConfidence: Specify the confidence level for your analysis. This level, which complements the significance level, dictates when to reject the null hypothesis and, consequently, the amount of work needed to approve the population. A higher confidence level necessitates more audit evidence to conclude that the population is free of material misstatement. In this example, we use a confidence level of 95%.\nExpected misstatements: Specify the number of misstatements tolerated in the sample. This means that if you find the specified number of misstatements in the sample, you can still approve the population. In this example, we tolerate a single misstatement, so we specify this setting to an absolute value of 1.\nPopulation: No. units: Specify the number of sampling units in the population. If you intend to select monetary units, this represents the total value of the population. If you plan to select items, this refers to the number of items in the population. In this case, we intend to use monetary unit sampling and hence we fill in the total population value of €1,000,000 here.\nAudit risk model: Indicate the risks of material misstatement using the audit risk model. This model helps reduce the required confidence level for the audit sampling procedure (1 - detection risk) by assessing inherent risk, control risk, and analytical risk. This results in less persuasive audit evidence being required. The model is expressed as: \\[\\text{Audit\\,risk} = \\text{Inherent\\,risk} \\times \\text{Control\\,risk} \\times \\text{Analytical\\,risk} \\times \\text{Detection\\,risk}\\]. Inherent risk, control risk, and analytical risk are typically evaluated on a 3-point scale: high, medium, and low. These assessments are mapped onto percentages based on professional judgment. The standard percentages used by JASP for Audit are based on those used by the Dutch independent government auditor and are provided in the output table below.\n\n\n\n\n\nIn this example, let’s assume we have conducted internal control testing, enabling us to set the internal control risk to ‘Medium’, which corresponds to 52%. Consequently, the detection risk can be calculated as \\(\\frac{0.05}{1 \\times 0.52 \\times 1}\\) = 9.6%.\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\n\n\n\n2.2.2 Main output\nThe main table in the output below displays the performance materiality as a proportion, along with the probabilities for the audit risk model. In this scenario, the detection risk is 9.6%. The second-to-last row indicates the tolerable misstatements as a number, showing that only a single misstatement is allowed in the sample. The final row presents the minimum sample size required to meet the sampling objectives, which is 130 units in this case. The note below the table clarifies that this sample size is determined using the binomial distribution (check out the ‘Advanced’ section for alternative methods).\n\n\n\n\n\n\n\n2.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nPlots: Compare sample sizes: This setting generates two figures. The first figure illustrates the minimum sample size under three statistical distributions commonly used in statistical auditing: the Poisson distribution, the binomial distribution, and the hypergeometric distribution. The second figure displays the minimum sample size for various tolerable misstatements.\n\n\n\n\n\nPlots: Presumed data distribution: This figure illustrates the presumed distribution of misstatements in the sample under the hypothesis of material misstatement in the population. The red bar highlights the tolerable misstatements, which together have a probability lower than the detection risk. In this scenario, the figure visualizes that if the population contains material misstatement, there is a 1.9% + 7.7% = 9.6% probability of observing zero or one misstatements in the sample of 130 units. This probability is sufficiently low to reject the hypothesis of tolerable misstatement.\n\n\n\n\n\nFormat output: This setting lets you choose whether certain numbers in the tables are displayed as proportions or percentages.\n\n\n\n2.2.4 Advanced\nThe following advanced settings enable you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nLikelihood: The likelihood is the distribution used to calculate the probabilities of observing a certain number of misstatements. The hypergeometric likelihood (available only if ‘No. units’ is filled in) assumes a finite population and results in smaller sample sizes for small populations. The binomial and Poisson distributions yield similar sample sizes when the population is large.\nIterations: Increment: Select the step size for the sample sizes to be considered. For example, a value of 5 will include sample sizes of 5, 10, 15, etc., while a value of 20 will include sample sizes of 20, 40, 60. The default value for this setting is 1, which considers all possible sample sizes.\nIterations: Maximum: Choose the maximum sample size to be considered. The analysis will stop if the sample size exceeds this value. The default value is 5000.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planning</span>"
    ]
  },
  {
    "objectID": "chap-planning.html#bayesian-planning",
    "href": "chap-planning.html#bayesian-planning",
    "title": "2  Planning",
    "section": "2.3 Bayesian planning",
    "text": "2.3 Bayesian planning\nThe Audit module includes an analysis called ‘Bayesian Planning,’ which is the Bayesian variant of the planning analysis. This enhanced analysis offers additional options beyond those available in the classical planning analysis, emphasizing the integration of various types of pre-existing audit information.\n\n2.3.1 Prior\nThese settings enable you to customize how different types of pre-existing audit information are integrated into the statistical analysis. For more details on the theory behind Bayesian planning and the types of prior distributions, read the corresponding section in Statistical Audit Sampling with R.\n\n\n\n\n\n\nDistribution: Select the functional form of the prior distribution. The default is the beta distribution, which is conjugate to the binomial likelihood. Other options include the gamma distribution (conjugate to the Poisson likelihood) and the beta-binomial prior distribution (conjugate to the hypergeometric likelihood).\nElicitation: Method: Choose the type of pre-existing information to be included in the prior distribution. By default, an ‘uninformative’ prior distribution is used, which incorporates negligible information. Alternatively, the prior distribution can be based on an earlier sample, risk assessments from the Audit Risk Model, or the assumption of impartiality.\nMost likely misstatement: Indicate the mode of the prior distribution, which represents the expected most likely misstatement in the population. Keep in mind that this differs from the tolerable deviation rate in the sample. This option is necessary only when the ‘Impartial’ or ‘Risk assessments’ elicitation method is chosen.\n\n\n\n2.3.2 Report\nThe following settings enable you to expand the report in the Bayesian planning analysis with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Prior and posterior: Check this box to generate a table displaying descriptive statistics of the prior distribution and the expected posterior distribution, which represents the posterior distribution if the planned sample is observed.\n\n\n\n\n\nPlots: Prior (and posterior) distribution: Check this box to generate a figure displaying the prior distribution. If the box for the posterior distribution is also checked, the figure will include the posterior distribution after observing the expected sample.\n\n\n\n\n\nPlots: Prior predictive distribution: Check this box to generate a figure displaying the prior predictive distribution, which illustrates the probabilities of a certain number of misstatements in the sample based on the prior distribution. This can help you verify if the prior distribution is reasonable at the data level.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Planning</span>"
    ]
  },
  {
    "objectID": "chap-selection.html",
    "href": "chap-selection.html",
    "title": "3  Selection",
    "section": "",
    "text": "3.1 Purpose of the analysis\nThis chapter is about the ‘Selection’ analysis in the ‘Audit Sampling’ section of the module.\nThe main goal of the selection analysis is to draw a representative sample of items from the population. These items can then be marked in the population file so they can be easily identified and tested. Particularly in an audit context, special sampling methods, such as monetary unit sampling, are used to ensure the sample has specific characteristics or meets certain criteria, such as always including items with a high book value.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Selection</span>"
    ]
  },
  {
    "objectID": "chap-selection.html#practical-example",
    "href": "chap-selection.html#practical-example",
    "title": "3  Selection",
    "section": "3.2 Practical example",
    "text": "3.2 Practical example\nLet’s explore an example of a selection analysis. To follow along, open the ‘Testing for Overstatements’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Testing for Overstatements’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 3500 rows and three columns: ‘ID’, ‘bookValue’, and ‘auditValue’. The ‘ID’ column represents the identification number of the items in the population. The ‘bookValue’ column shows the recorded values of the items, while the ‘auditValue’ column displays the true values. The ‘auditValue’ column is included for illustrative purposes, as auditors typically know the true values only for the audited sample, not for all items in the population.\n\n\n\n\n\n\n3.2.1 Main settings\nIn this example, we aim to select a sample of 50 monetary units from the population using monetary unit sampling with a fixed interval. To draw this sample, we open the ‘Selection’ analysis within the Audit module. The interface for the selection analysis is displayed below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariables: Start by entering the variable that holds the identification numbers for the items into the ‘Item ID’ field. Additionally, since we are performing monetary unit sampling, enter the variable ‘bookValue’ into the ‘Book Value’ field. Any variables you enter into the ‘Additional Variables’ field will be displayed along with the selected items in any output tables.\nSample size: Specify the number of sampling units you want to select from the population. In this example, we aim to test a sample of 100 monetary units, so we enter the value 50 in this field.\nSeed: A seed in computing is a starting point for generating random numbers. By setting a seed, you ensure that the results of the selection procedure can be reproduced across computers, which is useful for sharing your analysis.\nRandomize item order: Choose whether to randomly shuffle the items in the population before starting the selection process. This can help eliminate any patterns that may exist in the dataset. It’s generally a good idea to use this setting, so we enable it in this example.\nSampling units: Choose the type of sampling units you want to select. Selecting ‘Items’ will perform attribute sampling, while ‘Monetary units’ will perform monetary unit sampling. Since we have access to book values in this example, we select ‘Monetary units’.\nSelection method: Choose the selection algorithm. Since we want to sample monetary units using a fixed interval, we select ‘Fixed interval sampling’.\n\nFixed interval sampling: Starting point: This setting determines the starting point in the first interval. To enhance randomness, we set it to ‘Random’. Alternatively, we could choose a specific starting point by selecting the ‘Custom’ option.\n\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\n\n\n\n3.2.2 Main output\nThe first main table in the output, shown below, displays the number of selected units and the number of items from which these units were chosen. In this example, 50 sampling units have been selected across 50 items. Additionally, the table shows the total value of the items in the sample and the percentage of the population value that these sample items represent. The 50 items have a total value of €27,998.55, which is 2% of the total population value of €1,403,220.82, as calculated by 27,998.55 / 1,403,220.82 = 0.01995. The note under the table shows that the length of a single interval is €28,064.42.\n\n\n\n\n\nThe second main table in the output provides details specific to interval selection methods. It divides the population into two strata: the top stratum, which includes all items with a book value greater than a single interval of €28,064.42 (the top stratum limit would be two interval lenghts for cell sampling), and the bottom stratum, which contains items with a book value smaller than €28,064.42. In this example, there are no items with a book value exceeding €28,064.42, so the top stratum is empty.\n\n\n\n\n\n\n\n3.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Descriptive statistics: Checking this box generates a table of descriptive statistics (e.g., mean, median, standard deviation) for the variable in the ‘Book Value’ field and all variables in the ‘Additional Variables’ field. This can be used to gain insights into the distribution and characteristics of the sample.\n\n\n\n\n\nTables: Selected items: Checking this box generates a table that lists all the selected items in the sample along with their corresponding book values, if this variable is provided.\n\nOrder by book value: This setting enables you to sort the items in the table based on their book value, with the option to arrange them in either ascending or descending order. In this example, we sorted the book values in descending order.\n\n\n\n\n\n\n\n\n\n3.2.4 Export\nThe following settings enable you to isolate and export the selected items to a .csv file.\n\n\n\n\n\n\nColumn name selection result: Enter the name of the column that will be added to the population file. This column will contain the results of the selection procedure, indicating whether the item is selected for the sample and how many times it is included.\nFile name: Click ‘Browse’ to choose a location on your computer where you want to save the sample list.\nEnable synchronization: Finally, click on this setting to create the .csv file on your computer. When this setting is enabled, any changes you make to the sample by adjusting settings in the interface will be immediately reflected in the .csv file. If you prefer not to have this automatic update, uncheck this box after enabling it initially.\n\nAfter applying these settings, you should find the resulting .csv file saved on your computer.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Selection</span>"
    ]
  },
  {
    "objectID": "chap-evaluation.html",
    "href": "chap-evaluation.html",
    "title": "4  Evaluation",
    "section": "",
    "text": "4.1 Purpose of the analysis\nThis chapter is about the ‘Evaluation’ analysis in the ‘Audit Sampling’ section of the module.\nThe purpose of the evaluation analysis is to estimate the misstatement in the population from an audited sample and, if necessary, determine if the misstatement is below the performance materiality threshold. This enables auditors to conclude, with a certain level of assurance, whether the population is free of material misstatement.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-evaluation.html#practical-example",
    "href": "chap-evaluation.html#practical-example",
    "title": "4  Evaluation",
    "section": "4.2 Practical example",
    "text": "4.2 Practical example\nLet’s explore an example of an evaluation analysis. To follow along, open the ‘Evaluating a Sample’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Evaluating a Sample’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 90 rows and three columns: ‘ID’, ‘Book.value’, ‘Audit.value’. The ‘ID’ column represents the identification number of the items in the population. The ‘Book.value’ and ‘Audit.value’ columns show the recorded and true values of the items, respectively. The sample is drawn from a population of 1,414 items. In this scenario, we seek to determine, with 95% confidence, whether the population contains no misstatements exceeding the performance materiality threshold of 3.5% of the total population value, which amounts to €4,254,246.09.\n\n\n\n\n\n\n4.2.1 Main settings\nTo evaluate this audit sample, we open the ‘Evaluation’ analysis within the Audit module. The interface for the evaluation analysis is displayed below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariables: Begin by entering the variable that contains the identification numbers for the items into the ‘Item ID’ field. Then, input the variables that hold the book values and audit (true) values of the items into their respective fields. If your data includes an indicator for which items are part of the sample, drag this to the ‘Selection Counter’ box. Similarly, if there’s an indicator identifying the stratum to which an item belongs, drag this to the ‘Stratum’ box.\nSampling objectives: Performance materiality: In this section, you can input the performance materiality either as a percentage (relative) or as a monetary amount (absolute). For this example, we enter the performance materiality as a relative value of 3.5%.\nSampling objectives: Minimum precision: This objective requires that the misstatement in the population is estimated with a specified minimum uncertainty (the difference between the most likely misstatement and the upper limit for the misstatement). Since this is not relevant to our audit objective, we leave this box unchecked.\nConfidence: Specify the confidence level for your analysis. This level, which complements the significance level, dictates when to reject the null hypothesis and the amount of work needed to approve the population. A higher confidence level requires more audit evidence to conclude that the population is free of material misstatement. In this example, we use a confidence level of 95%.\nData type: Indicate the type of data you are working with. The ‘Population’ data type assumes that the loaded data file is a full population, with selected items indicated via the ‘Selection Counter’ variable. This removes the need to manually enter the number of items and units in the population. The ‘Sample’ data type assumes that the loaded data file is a sample list and requires entering the number of items and units in the population manually. The ‘Summary statistics’ data type eliminates the need to load a data file and enter variables, assuming the data comes in the form of two values: the sample size and the number of misstatements.\nPopulation: No. items: Enter the number of items in the population. In this example, the population consists of 1,414 items, so we input the value 1,414 here.\nPopulation: No. units: Enter the total value of the population. In this example, the population has a total value of €4,254,246.09, so we input the value 4,254,246.09 here.\nAudit risk model: Input the assessed risks of material misstatement into the Audit Risk Model here. For further details on this setting, refer to Chapter 2.\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\n\n\n\n4.2.2 Main output\nThe main table in the output below shows the performance materiality (and minimum precision if enabled), along with the sample size and the number of identified misstatements in the sample. The ‘Taint’ row displays the sum of the taints, which are the fractional misstatements of the items. Finally, the table presents the estimated most likely misstatement in the population, the 95% upper bound, and the associated precision (the difference between the most likely misstatement and the upper bound).\n\n\n\n\n\nIn this example, the sample consisted of 90 items, with one misstatement identified. This misstatement had a taint of 0.110. Consequently, the most likely misstatement in the population is estimated to be 0.001, or 0.1%. The 95% upper bound for this estimate is 0.035, or 3.5%, and the precision is 3.4%. This upper bound matches the performance materiality of 3.5%, indicating that the auditor has achieved at least 95% assurance that the population is free of material misstatement.\n\n\n4.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Misstated items: Check this box to generate a table displaying the misstated items in the sample. In this instance, the single misstated item had a book value of €1,813.42 and an audit (true) value of €1,613.42, resulting in a misstatement of €200 and a taint of 0.110.\n\n\n\n\n\nTables: Corrections to population: Check this box to generate a table indicating the necessary corrections to the population to meet a specific objective. For example, to ensure the population is free of misstatements with 95% confidence, a correction of the upper limit to 3.5% of the population value is required.\n\n\n\n\n\nPlots: Sampling objectives: Check this box to generate a figure displaying the sampling objectives, the most likely error, and the upper bound. In this case, the sole sampling objective was the performance materiality. Since the upper bound is lower than the performance materiality, it is highlighted in green.\n\n\n\n\n\nPlots: Estimates: Check this box to generate a figure displaying the most likely misstatement along with the upper and lower limits. This figure is generally useful only if you have entered a variable in the ‘Stratum’ box, as it provides a quick visual overview of the magnitude of the misstatement in the various strata.\n\n\n\n\n\n\n\n\n4.2.4 Advanced\nThe following advanced settings enable you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nMethod: Choose the statistical method to calculate the upper limit of the misstatement. In this example, we selected the Stringer bound as the evaluation method because it considers the taints of the items, making it less conservative than the Poisson, binomial, and hypergeometric distributions. Note that the default setting is ‘Binomial’, so you must manually select the Stringer bound if you wish to use it.\nCritical items: Choose which items are excluded from the statistical evaluation and designated as critical items. Currently, the only option is to mark negative values as critical items, which are kept by default and subtracted from the most likely misstatement and upper bound.\nConfidence interval (Alt. hypothesis): Choose whether to calculate a one-sided confidence interval (upper bound or lower bound) or a two-sided confidence interval for the population misstatement. This selection determines the alternative hypothesis being tested.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-evaluation.html#bayesian-evaluation",
    "href": "chap-evaluation.html#bayesian-evaluation",
    "title": "4  Evaluation",
    "section": "4.3 Bayesian evaluation",
    "text": "4.3 Bayesian evaluation\nThe Audit module includes an analysis called ‘Bayesian Evaluation,’ which is the Bayesian variant of the evaluation analysis. This enhanced analysis offers additional options beyond those available in the classical evaluation analysis, emphasizing the integration of various types of pre-existing audit information.\n\n4.3.1 Prior\nThese settings enable you to customize how different types of pre-existing audit information are integrated into the statistical analysis. For more details on the theory behind Bayesian evaluation and the types of prior distributions, read the corresponding section in Statistical Audit Sampling with R.\n\n\n\n\n\n\nDistribution: Select the functional form of the prior distribution. The default is the beta distribution, which is conjugate to the binomial likelihood. Other options include the gamma distribution (conjugate to the Poisson likelihood) and the beta-binomial prior distribution (conjugate to the hypergeometric likelihood).\nElicitation: Method: Choose the type of pre-existing information to be included in the prior distribution. By default, an ‘uninformative’ prior distribution is used, which incorporates negligible information. Alternatively, the prior distribution can be based on an earlier sample, risk assessments from the Audit Risk Model, or the assumption of impartiality.\nMost likely misstatement: Indicate the mode of the prior distribution, which represents the expected most likely misstatement in the population. Keep in mind that this differs from the tolerable deviation rate in the sample. This option is necessary only when the ‘Impartial’ or ‘Risk assessments’ elicitation method is chosen.\n\n\n\n4.3.2 Report\nThe following settings enable you to expand the report in the Bayesian evaluation analysis with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Prior and posterior: Check this box to generate a table displaying descriptive statistics of the prior distribution and the realized posterior distribution.\n\n\n\n\n\nPlots: Sequential analysis: Check this box to produce a figure showing the Bayes factor as a function of the sample size.\n\n\n\n\n\nPlots: Prior and posterior: Check this box to generate a figure displaying the prior and posterior distribution. If the box for additional information distribution is also checked, the figure will include information about the posterior distribution and the Bayes factor.\n\n\n\n\n\n\n\n\n4.3.3 Advanced\nThe following advanced settings enable you to customize the statistical computations in the Bayesian evaluation analysis according to your preferences.\n\n\n\n\n\n\nAlgorithm: Partial projection: Check this box to separate the observed misstatement from the unobserved misstatement during evaluation, projecting the uncertainty only onto the unobserved portion of the population.\nAlgorithm: Share information: Check this box to apply a hierarchical model when analyzing a stratified sample. To enable this option, you must specify a variable in the ‘Stratum’ box.\nAlgorithm: Hurdle model: Select this option to apply the hurdle model, an alternative evaluation method. This approach is a Bayesian alternative to the Stringer bound because it properly accounts for the partial misstatements in the items.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Evaluation</span>"
    ]
  },
  {
    "objectID": "chap-estimation.html",
    "href": "chap-estimation.html",
    "title": "5  True Value Estimation",
    "section": "",
    "text": "5.1 Purpose of the analysis\nThis chapter is about the ‘True Value Estimation’ analysis in the ‘Audit Sampling’ section of the module.\nThe objective of the true value estimation analysis is to estimate the true value of the population based on a sample. This procedure is commonly used when an audit sample contains many misstatements. In such cases, the auditor cannot conclude that the population is free of material misstatement but aims to estimate its true value. The estimation procedures in this analysis assume a minimum of 30 misstatements in the sample.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>True Value Estimation</span>"
    ]
  },
  {
    "objectID": "chap-estimation.html#practical-example",
    "href": "chap-estimation.html#practical-example",
    "title": "5  True Value Estimation",
    "section": "5.2 Practical example",
    "text": "5.2 Practical example\nLet’s explore an example analysis of a true value estimation analysis. To follow along, open the ‘Evaluating a Stratified Sample’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Evaluating a Stratified Sample’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 1414 rows and five columns: ‘ID’, ‘Stratum’, ‘BookValue’, ‘AuditValue’, and ‘Selected’, which represents a population. The ‘ID’ column represents the identification number of the items in the population. The ‘Stratum’ column shows the location from which the item was retrieved. The ‘BookValue’ and ‘AuditValue’ columns show the recorded and true values of the items, respectively. Finally, the ‘Selected’ column shows which items were selected to be included in the sample. The total value of the population (i.e., the sum of the ‘BookValue’ column) is €4,254,246,09. Note that the audit values of all items that were not selected in the sample (the value of ‘Selected’ is 0) are empty (NA).\n\n\n\n\n\n\n5.2.1 Main settings\nIn this example, we want to estimate the true value of the population based on the audite sample. To do this, we open the ‘True Value Estimation’ analysis within the Audit module. The interface for this analysis is displayed below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariables: First, enter the variables indicating the book values and audit (i.e., true) values of the sample items in the corresponding box.\nPopulation: No. items: Enter the number of items in the population. In this example, the population consists of 1,414 items, so we input the value 1,414 here.\nPopulation: No. units: Enter the total value of the population. In this example, the population has a total value of €4,254,246.09, so we input the value 4,254,246.09 here.\nMethod: Select the statistical method for estimating the true value (Touw & Hoogduin, 2012). The regression estimator is typically the most accurate method, so we choose this method here.\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\nDisplay: Confidence: Set the confidence level used in the explanatory text. In this example, we use a confidence level of 95%.\n\n\n\n5.2.2 Main output\nThe main table in the output below presents the point estimate for the true population value, along with the uncertainty of the estimate and its 95% confidence interval. In this example, the true value of the population is estimated to be €2,512,392.17, with an uncertainty of €551,398.32. Therefore, we can be 95% confident that the true value of the population lies between €1,960,993.85 and €3,063,790.49. The confidence interval does not include the recorded population value of €4,254,246.09.\n\n\n\n\n\n\n\n5.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Required sample size: Checking this box calculates the required sample size to achieve a specific level of uncertainty in the estimate. For example, the current uncertainty in the estimate is €551,398.32. The table below indicates that to reduce this uncertainty to €500,000, a total sample of 459 items is needed. Since we have already sampled 400 items, only 59 additional samples are required.\n\n\n\n\n\nPlots: Scatter plot: Checking this box generates a figure that compares the book values of the items in the sample against their true values. Points on the diagonal, shown in gray, represent items where the book value matches the true value. Points in red indicate items where the book value does not match the true value. The black line represents the Pearson correlation between the book values and audit values, which in this case is r = 0.7.\n\n\n\n\n\n\n\n\n\n\n\n\nTouw, P., & Hoogduin, L. (2012). Statistiek voor audit en controlling. Boom.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>True Value Estimation</span>"
    ]
  },
  {
    "objectID": "chap-howto-sampling.html",
    "href": "chap-howto-sampling.html",
    "title": "6  How-to’s",
    "section": "",
    "text": "6.1 Extending a sample selected with a fixed interval\nThis chapter contains various step-by-step instructions on how to perform best practices using the analyses in the ‘Audit Sampling’ section of the module.\nIf you have selected a sample using a fixed interval and need to extend it because your population has become larger, follow these steps to manually create a selection counter column. Click the ‘+’ icon next to the dataset and select ‘Compute column’.\nNext, name the new column (for example, ‘Selected_for_sample’), then click the R icon, followed by the ‘scale’ icon, and click on ‘Create column’. This will open an editor where you can input the necessary R code.\nCopy and paste the following R script into the editor, ensuring that you replace the first three lines with the appropriate values for your dataset. The interval represents the fixed interval size, start defines the starting point within the first interval, and book_values should be replaced with the column name containing your book values.\nFor example, if you are selecting with an interval of €15,000 and a starting point of 1, you should enter the following values.\nIf you later extend your dataset by adding new data, you must re-run the computed column to update the selection while maintaining the same interval (e.g., €15,000).",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How-to's</span>"
    ]
  },
  {
    "objectID": "chap-howto-sampling.html#extending-a-sample-selected-with-a-fixed-interval",
    "href": "chap-howto-sampling.html#extending-a-sample-selected-with-a-fixed-interval",
    "title": "6  How-to’s",
    "section": "",
    "text": "interval &lt;- ... # Specify the size of the fixed interval\nstart &lt;- ... # Specify the starting point in the first interval\nbook_values &lt;- ... # Enter the name of the column containing book values\n\n# Do not change the code below\nsize &lt;- sum(book_values) %/% interval; units &lt;- start + interval * (0:(size - 1)); cumsum_values &lt;- cumsum(book_values)\nitems &lt;- rep(0, size)\nfor (i in 1:size) items[i] &lt;- which(units[i] &lt;= cumsum_values)[1]\nresult &lt;- rep(0, length(book_values)); counts &lt;- table(items); indices &lt;- as.integer(dimnames(counts)[[1]]); result[indices] &lt;- as.numeric(counts)\nresult",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How-to's</span>"
    ]
  },
  {
    "objectID": "chap-howto-sampling.html#configurating-and-locking-default-options",
    "href": "chap-howto-sampling.html#configurating-and-locking-default-options",
    "title": "6  How-to’s",
    "section": "6.2 Configurating and locking default options",
    "text": "6.2 Configurating and locking default options\nYou can launch JASP with a configuration file to set restrictions, disable, or hide certain options from users. This is particularly useful for deploying JASP for Audit within your organization, ensuring control over the options available to less statistically experienced users.\nThe configuration file type is .toml. The example .toml file below sets the likelihood in the classical planning analysis to the Poisson distribution and locks the option, preventing it from being changed. Additionally, it specifies the increment (the option name in the QML file is ‘by’) as 1 and the maximum sample size (the option name in the QML file is ‘max’) as 2,000 instead of the default 5,000.\nFormat = \"0.1.0\"\nJASPVersion = \"0.19.3\"\n\nEnabledModules = [\"jaspAudit\"]\n\n[Modules.jaspAudit.Analyses.auditClassicalPlanning.Options]\nlikelihood = {Value = \"poisson\", Lock = true}\nby = {Value = 1, Lock = true}\nmax = {Value = 2000, Lock = true}\nTo load this config file into JASP, go to ‘Preferences’ in the left menu, then ‘Advanced’, and click ‘Use a configuration file’ in the ‘Configuration File Options’ box. Select the location of your config file and restart JASP for the changes to take effect.\n\n\n\n\n\nWhen you start the planning analysis, the options under advanced settings will be set to the corresponding defaults and cannot be changed by the user.",
    "crumbs": [
      "Audit Sampling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How-to's</span>"
    ]
  },
  {
    "objectID": "chap-benford.html",
    "href": "chap-benford.html",
    "title": "7  Benford’s Law",
    "section": "",
    "text": "7.1 Purpose of the analysis\nThis chapter is about the ‘Benford’s Law’ analysis in the ‘Data Auditing’ section of the module.\nBenford’s law states that the distribution of leading digits in a population naturally follows a certain distribution. Specifically, the frequencies of each leading digit d are defined by p(d) = log\\(_{10}\\)(1 + \\(\\frac{1}{d}\\)), see the figure below. For instance, the probablity of observing a 1 as a leading digit is 0.301, or 30.1%. This can be tested in a statistical manner. That is, the null hypothesis, H\\(_0\\), states that the distribution of first digits follows Benford’s law, while the alternative hypothesis, H\\(_1\\), states that it does not.\nThe purpose of the analysis in JASP is to investigate whether the distribution of first, second, or last digits in a set of numbers follows Benford’s law. In auditing, this may provide evidence that certain items or transactions in a population might warrant further investigation.",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Benford's Law</span>"
    ]
  },
  {
    "objectID": "chap-benford.html#practical-example",
    "href": "chap-benford.html#practical-example",
    "title": "7  Benford’s Law",
    "section": "7.2 Practical example",
    "text": "7.2 Practical example\nLet’s explore an example analysis of Benford’s law. To follow along, open the ‘Assessing Benford’s Law’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Assessing Benford’s Law’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 772 rows and two columns: ‘ID’ and ‘value’. The ‘ID’ column represents the identification number of the items in the population. The ‘value’ column shows the recorded values of the items.\n\n\n\n\n\n\n7.2.1 Main settings\nIn this example, we will investigate whether the distribution of first digits in the variable ‘value’, which represents the recorded values of transactions in a financial population, adheres to Benford’s law. That is, the null hypothesis, H\\(_0\\), states that the distribution of first digits follows Benford’s law, while the alternative hypothesis, H\\(_1\\), states that it does not. To test this, we open the ‘Benford’s Law’ analysis from the Audit module. The interface of the Benford’s law analysis is shown below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariable: Begin by entering the variable whose digit distribution you wish to test in the designated box. In the example, this is the variable ‘value’, so we drag this variable to the field on the right.\nConfidence: Indicate the confidence level for your analysis. This level, which complements the significance level, determines when to reject the null hypothesis. In the example, we use a confidence level of 95%.\nReference: Select a reference distribution to compare the chosen digits against. By default, this is set to ‘Benford’s law,’ but you can also opt for a uniform distribution. In the example, we select ‘Benford’s law’.\nDigits: Choose which digits to compare against the reference distribution. You can select the first digits (default), the first two digits, or the last digits. Benford’s law typically applies to the first or first two digits, while the uniform distribution is usually applied to the last digits. In the example, we choose to test the first digits against Benford’s law.\nBayes factor: Select which Bayes factor is displayed in the main output table. ‘BF\\(_{10}\\)’ represents the Bayes factor in favor of the alternative hypothesis over the null hypothesis, ‘BF\\(_{01}\\)’ represents the Bayes factor in favor of the null hypothesis over the alternative hypothesis, and ‘Log(BF\\(_{10}\\))’ represents the logarithm of BF\\(_{10}\\).\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\n\n\n\n7.2.2 Main output\nThe main table in the output, shown below, shows the sample size (n), the mean absolute deviation (MAD), the chi-square value (\\(X^2\\)) and its degrees of freedom (df). The table shows a p-value of 0.478, indicating that H\\(_0\\) should not be rejected at a significance level of 5%. Furthermore, the table presents the Bayes factor in favor of the null hypothesis, BF\\(_{01}\\), which is 6.9x10\\(^6\\). This suggests that the data provide very strong evidence supporting H\\(_0\\) over H\\(_1\\).\n\n\n\n\n\nNote that non-conformity to Benford’s law does not necessarily indicate fraud. A Benford’s law analysis should therefore only be used to acquire insight into whether a population might need further investigation.\n\n\n7.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Frequency table: Check this box to display a table of the observed and expected frequencies of the digits. Clicking the ‘Confidence interval’ option shows confidence intervals for the observed relative frequencies in the table.\nThe frequency table displays the observed count for each leading digit in the second column. Adjacent to this, it shows the expected relative frequency under Benford’s law alongside the observed relative frequency in the data. Additionally, p-values and Bayes factors are provided to test whether the observed relative frequencies differ from the expected ones. In this case, only the digit 8 has a p-value smaller than 0.05, indicating a significant deviation from the expected relative frequency under Benford’s law.\n\n\n\n\n\nTables: Matched rows: Check this box to display a table showing the rows that have a certain number as their leading/last digit(s).\nIn the example, we request a table of rows that match the digit 8. The first column displays the row number where the digit is found, and the second column shows the matched value. Using this table, you can identify the transactions that may warrant further investigation.\n\n\n\n\n\nPlots: Observed vs. expected: Check this box to display a figure that illustrates the observed frequencies compared to the expected frequencies.\nThe figure in the output visualizes the observed relative frequencies compared to the expected ones, with the digit 8 highlighted in red. From this figure, it is immediately clear that the transactions starting with the digit 8 may warrant further inspection.\n\n\n\n\n\nPlots: Bayes factor robustness check: Check this box to display a figure that shows the Bayes factor under different specifications of the prior concentration parameter.\nThe figure below is referred to as a robustness check. If the Bayes factor supports a particular hypothesis across all reasonable values of the prior concentration parameter, the result is considered robust regarding the choice of prior distribution. In this instance, the figure demonstrates that the Bayes factor consistently provides evidence in favor of the null hypothesis, regardless of the prior concentration parameter values.\n\n\n\n\n\nPlots: Sequential analysis: Select this box to display a figure illustrating the Bayes factor as a function of sample size, across various prior specifications.\nIn the example analysis, the sequential analysis plot demonstrates that the Bayes factor provides increasing evidence in favor of H\\(_0\\) as the sample size grows. Additionally, this evidence is more pronounced when using a more concentrated prior distribution.\n\n\n\n\n\n\n\n\n7.2.4 Advanced\nThe following advanced settings enable you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nPrior distribution: Concentration: Specify the concentration parameter for the Dirichlet prior distribution. Adjusting this value will alter the Bayes factor in the main output table. A larger concentration parameter indicates a more concentrated prior distribution, suggesting that the population proportions are more similar. When testing against the uniform distribution, this implies a stronger belief in H\\(_0\\). Conversely, when testing against Benford’s law, it indicates a stronger belief in H\\(_1\\).",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Benford's Law</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html",
    "href": "chap-bunching.html",
    "title": "8  Repeated Values",
    "section": "",
    "text": "8.1 Purpose of the analysis\nThis chapter is about the ‘Repeated Values’ analysis in the ‘Data Auditing’ section of the module.\nThe repeated values analysis examines the frequency of value repetitions within a dataset (referred to as “number-bunching”) to statistically determine if the data were likely tampered with (Simohnsohn, 2019). This can be tested statistically. The null hypothesis H\\(_0\\) posits that the data do not contain an unexpected amount of repeated values, while the alternative hypothesis H\\(_1\\) suggests they do. Unlike Benford’s law, this approach analyzes the entire number at once, not just the first or last digit.\nThe purpose of the analysis in JASP is to identify whether the data exhibit excessive repeated values. In auditing, this could indicate that certain items or transactions within a population may require further investigation.",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "chap-bunching.html#practical-example",
    "href": "chap-bunching.html#practical-example",
    "title": "8  Repeated Values",
    "section": "8.2 Practical example",
    "text": "8.2 Practical example\nLet’s explore an example analysis of repeated values. To follow along, open the ‘Assessing Benford’s Law’ dataset from the Data Library. Navigate to the top-left menu, click ‘Open’, then ‘Data Library’, select ‘7. Audit’, and finally click on the text ‘Assessing Benford’s Law’ (not the green JASP-icon button).\n\n\n\n\n\nThis will open a dataset with 772 rows and two columns: ‘ID’ and ‘value’. The ‘ID’ column represents the identification number of the items in the population. The ‘value’ column shows the recorded values of the items.\n\n\n\n\n\n\n8.2.1 Main settings\nIn this example, we will test whether the values in the ‘value’ column show an excessive amount of repeated values. To test this, we open the ‘Repeated Values’ analysis from the Audit module. The interface of the repeated values analysis is shown below.\n\n\n\n\n\nThese are the main settings for the analysis:\n\nVariable: Start by entering the variable whose digits should be analyzed for repeated values in the designated box. In this example, the variable is ‘value’, so we drag this variable to the field on the right.\nTests: Average frequency Check this box to test if the average frequency of values differs from what is expected. In this example, we only examine the average frequency, so we check this box.\nTests: Entropy Check this box to test if the entropy of values differs from what is expected. In this example, we do not check this box as we are only looking at the average frequency.\nShuffle decimal digits: This setting determines which decimal digits are shuffled in the analysis. In this example, we select all decimal digits to be shuffled.\nDisplay: Explanatory text: Finally, select whether to show explanatory text in the output.\nDisplay: Confidence: Set the confidence level used in the explanatory text. In this example, we use a confidence level of 95%.\n\n\n\n8.2.2 Main output\nThe main table in the output below displays the sample size (n), the average frequency of 1.324, and the p-value for the test. This indicates that each unique value in the data occurs, on average, 1.324 times. The p-value is smaller than the significance level of 5%, leading us to reject the null hypothesis and conclude that there is an excessive amount of repeated values in the data.\n\n\n\n\n\nNote that rejecting the null hypothesis does not necessarily indicate fraud. A repeated values analysis should therefore only be used to acquire insight into whether a population might need further investigation.\n\n\n8.2.3 Report\nThe following settings enable you to expand the report with additional output, such as tables and figures.\n\n\n\n\n\n\nTables: Assumption checks: To quantify expectations, this test assumes that the integer portions of the numbers are not correlated with their decimal portions. The table below tests this assumption and confirms it holds, as indicated by the non-significant p-value of 0.461.\n\n\n\n\n\nTables: Frequency table: The frequency table displays the occurrence of each unique value in the data, ordered from highest to lowest frequency. For example, it shows that the value 87,670 appeared five times, representing 0.6% of the total values.\n\n\n\n\n\nPlots: Observed vs. expected: Check this box to generate a histogram of the expected distribution of the average frequency or entropy, assuming the decimal portions of the numbers are random and not associated with their integer portions. The observed average frequency will be indicated in the figure.\n\n\n\n\n\nPlots: Histogram: The histogram visualizes the frequency table using bars to represent the values. Similar to the frequency table, the histogram indicates that the most frequently occurring value is 87,670, which appears five times.\n\n\n\n\n\n\n\n\n8.2.4 Advanced\nThe following advanced settings enable you to customize the statistical computations according to your preferences.\n\n\n\n\n\n\nBootstrap: Number of samples: This setting specifies the number of bootstratp samples used to compute the expected distribution of the average frequency or the entropy. The default value for this setting is 500.\nBootstrap: Seed: A seed in computing is a starting point for generating random numbers. By setting a seed, you ensure that the results of the analysis can be reproduced across computers, which is useful for sharing your analysis.\n\n\n\n\n\n\n\nSimohnsohn, U. (2019). Number-bunching: A new tool for forensic data analysis. http://datacolada.org/77",
    "crumbs": [
      "Data Auditing",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Repeated Values</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Derks, K. (2025). jfa: Statistical\nmethods for auditing. https://doi.org/10.32614/CRAN.package.jfa\n\n\nDerks, K., de Swart, J., Wagenmakers, E., Wille, J., & Wetzels, R.\n(2021). JASP for Audit: Bayesian\ntools for the auditing practice. Journal of Open Source\nSoftware, 6(68), 2733.\n\n\nDerks, K., Swart, J. de, & Wetzels, R. (2023). Open-source software\nals brug tussen de auditor en de statisticus. Maandblad Voor\nAccountancy En Bedrijfseconomie, 97(1/2), 17–28. https://doi.org/10.5117/mab.97.87480\n\n\nJASP Team. (2025). JASP (Version\n0.19.3)[Computer software]. https://jasp-stats.org/\n\n\nSimohnsohn, U. (2019). Number-bunching: A new tool for forensic data\nanalysis. http://datacolada.org/77\n\n\nTouw, P., & Hoogduin, L. (2012). Statistiek voor audit en\ncontrolling. Boom.",
    "crumbs": [
      "References"
    ]
  }
]